# Arguments for the constructor of ProgramGenerator and QuestionReconstructor model
model_input_size: 256
model_hidden_size: 256
model_num_layers: 2
model_dropout: 0.0


# Optimization arguments (adam optimizer by default)
optim_num_iterations: 18000
optim_weight_decay: 0.000
optim_batch_size: 256

### Learning rate scheduling - (lr *= gamma) if program generation accuracy plateaus
optim_lr_initial: 0.001
optim_lr_gamma: 0.5
optim_lr_patience: 3


# Question coding hyper parameters
qc_num_supervision: 1000

### Question length in CLEVR can be upto 45 - too much variance in lengths for less supervision.
qc_supervision_question_max_length: 40

qc_alpha: 100.0
qc_beta: 0.1
qc_delta: 0.99

### Optimization objective, "baseline": just train a program generator on examples with
### supervision. "ours": optimize the whole question coding objective.
qc_objective: "ours"
qc_average_loss_across_timesteps: true
qc_average_logprobs_across_timesteps: true


# Arguments for the constructor of ProgramPrior model
prior_checkpoint: "data/program_prior_best_checkpoint.pth"  # ppl: 2.600
prior_input_size: 256
prior_hidden_size: 256
prior_num_layers: 2
prior_dropout: 0.0
