RANDOM_SEED: 0
PHASE: joint_training

# Training objective, "baseline": just train a program generator on examples with
# supervision. "ours": optimize the whole question coding objective.
OBJECTIVE: ours
SUPERVISION: 1000
SUPERVISION_QUESTION_MAX_LENGTH: 40

# ALPHA, BETA, GAMMA, DELTA are not used when OBJECTIVE is "baseline".
ALPHA: 100.0
BETA: 0.1
GAMMA: 1.0
DELTA: 0.99

# Optimization arguments, we use Adam optimizer and ReduceLROnPlateau scheduler.
OPTIM:
  BATCH_SIZE: 256
  NUM_ITERATIONS: 10000
  WEIGHT_DECAY: 0.0

  # Learning rate scheduling: (lr *= gamma) if program generation accuracy plateaus.
  LR_INITIAL: 0.000001
  LR_GAMMA: 0.5
  LR_PATIENCE: 3

# Path to pre-trained checkpoints.
CHECKPOINTS:
  PROGRAM_PRIOR: checkpoints/program_prior_best.pth
  QUESTION_CODING: checkpoints/question_coding_1000_baseline_best.pth
  MODULE_TRAINING: checkpoints/module_training_1000_baseline_best.pth

# Arguments for the constructor of ProgramGenerator model (loaded from checkpoint).
PROGRAM_GENERATOR:
  INPUT_SIZE: 256
  HIDDEN_SIZE: 256
  NUM_LAYERS: 2
  DROPOUT: 0.0

# Arguments for the constructor of QuestionReconstructor model (loaded from checkpoint).
QUESTION_RECONSTRUCTOR:
  INPUT_SIZE: 256
  HIDDEN_SIZE: 256
  NUM_LAYERS: 2
  DROPOUT: 0.0

# Arguments for the constructor of ProgramPrior model (loaded from checkpoint).
PROGRAM_PRIOR:
  INPUT_SIZE: 256
  HIDDEN_SIZE: 256
  NUM_LAYERS: 2
  DROPOUT: 0.0

# Arguments for the constructor of NeuralModuleNetwork model (loaded from checkpoint).
NMN:
  IMAGE_FEATURE_SIZE: [1024, 14, 14]
  MODULE_CHANNELS: 128
  CLASS_PROJECTION_CHANNELS: 1024
  CLASSIFIER_LINEAR_SIZE: 1024
