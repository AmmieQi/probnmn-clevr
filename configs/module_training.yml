RANDOM_SEED: 0
PHASE: module_training

# Arguments for the constructor of NeuralModuleNetwork model
NMN:
  IMAGE_FEATURE_SIZE: [1024, 14, 14]
  MODULE_CHANNELS: 128
  CLASS_PROJECTION_CHANNELS: 1024
  CLASSIFIER_LINEAR_SIZE: 1024

# Optimization arguments, we use Adam optimizer (no LR scheduling here).
OPTIM:
  BATCH_SIZE: 128
  NUM_ITERATIONS: 80000
  WEIGHT_DECAY: 0.000

  LR_INITIAL: 0.0001

  # Learning rate scheduling is off here (very higher patience).
  LR_GAMMA: 0.5
  LR_PATIENCE: 1000000

# Path to pre-trained checkpoint of ProgramGenerator (from Question Coding).
# This checkpoint corresponds to SUPERVISION = 1000 and OBJECTIVE = "ours".
CHECKPOINTS:
  QUESTION_CODING: checkpoints/question_coding_1000_ours_best.pth

# Arguments for the constructor of ProgramGenerator model (loaded from checkpoint).
PROGRAM_GENERATOR:
  INPUT_SIZE: 256
  HIDDEN_SIZE: 256
  NUM_LAYERS: 2
  DROPOUT: 0.0
